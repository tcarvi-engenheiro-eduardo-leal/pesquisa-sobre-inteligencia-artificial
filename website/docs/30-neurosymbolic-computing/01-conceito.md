# Posicionamento da IA Neurosimb√≥lica
- Neurosymbolic Computing mostra-se como uma evolu√ß√£o natural do campo de IA, respondendo cr√≠ticas por confian√ßa e auditoria dos sistemas de IA baseados em redes neurais.
- O processamento Neurosimb√≥lico defende que deve-se usar s√≠mbolos e l√≥gica para resolver os limites t√©cnicos da Deep Learning (*brittleness* e falta de "entendimento l√≥gico"). A limita√ß√£o de *brittleness* indica que os modelos neurais LLM podem falhar de forma inesperada e perigosa, devido varia√ß√µes e incertezas presentes nos dados do mundo real. J√° o problema do entendimento representa o problema de l√≥gica n√£o percebida por probabilidade de sequ√™ncias de tokens.
- H√° atualmente, no √¢mbito acad√™mico, debate paradigm√°tico entre as escolhas por:
    - Representa√ß√µes Distribu√≠das Neurais
        - vs
    - Representa√ß√µes Localistas Simb√≥licas

## Artigo de Arthur D'√Åvila Garcez, Neuro-simbolic AI: The 3rd Wave
> Artur d‚ÄôAvila Garcez and Lu√≠s C. Lamb  
> City, University of London, UK  
> a.garcez@city.ac.uk  
> Federal University of Rio Grande do Sul, Brazil  
> luislamb@acm.org  
> December, 2020  

- Defende que a melhor forma de pensar o avan√ßo dos sistemas de IA n√£o √© com este debate paradigm√°tico, mas pensando na forma como o conhecimento deve ser representado para que se aprenda algo e para que se raciocine sobre algo.

- Com base no artigo "Neurosymbolic AI: The 3rd Wave" e no estado da arte sobre processamento neurosimb√≥lico:  

### üìú Princ√≠pios Fundamentais do Processamento Neurosimb√≥lico  

| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Integra√ß√£o H√≠brida & Simbi√≥tica** | Neuronal e simb√≥lico n√£o s√£o apenas conectados, mas se **potencializam**. O sistema usa o melhor de cada paradigma para tarefas espec√≠ficas. | Usa redes neurais para percep√ß√£o (vis√£o, linguagem) e l√≥gica para **racioc√≠nio** e **verifica√ß√£o/auditoria** . |
| 2. **Fundamenta√ß√£o de S√≠mbolos (Symbol Grounding)** | S√≠mbolos abstratos (ex: "cadeira") devem **emergir e ser ancorados** em dados do mundo real (imagens, sensa√ß√µes) processados pelas redes neurais. | Evita "**s√≠mbolos vazios**" **sem conex√£o sem√¢ntica com o mundo real**. |
| 3. **Composicionalidade & Generaliza√ß√£o** | O sistema deve poder **combinar conceitos aprendidos** para entender e gerar novas situa√ß√µes n√£o vistas durante o treinamento. | Entender "empurrar uma cadeira" ao **conhecer** "empurrar" e "cadeira". **O que significa, conforme processamento neurosimb√≥lico, entender "empurrar uma cadeira"?** |
| 4. **Explicabilidade por Design** | O racioc√≠nio deve ser **transparente e rastre√°vel**. Decis√µes podem ser explicadas tanto em termos de dados estat√≠sticos quanto de regras l√≥gicas. **A auditoria s√≥ pode ocorrer a partir da defini√ß√£o humana e codific√°vel de regras l√≥gicas.** | Fornecer cadeias de infer√™ncia (ex: "Classifiquei como fraude PORQUE a regra X foi violada"). |

### üõë Desafios Principais do Processamento Neurosimb√≥lico 

| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Barreira Representacional** | Conciliar **representa√ß√µes distribu√≠das** (neurais, sub-simb√≥licas) com **representa√ß√µes localistas** (simb√≥licas, l√≥gicas) em uma arquitetura **coesa** √© complexo. **Como codificar tal sistema?** | **Como um vetor neural se torna um s√≠mbolo discreto para o m√≥dulo l√≥gico manipular?** Como as diferentes frameworks atuais do mercado codificam esta convers√£o? Com filtros sobre os tokens e embeddings pr√©-processados, no fluxo vetorial da rede neural? **Como se codifica este processamento?** |
| 2. **Escalabilidade do Conhecimento** | Criar e manter **bases de conhecimento simb√≥lico** grandes e consistentes √© trabalhoso e dif√≠cil de automatizar totalmente. **Como verificar as regras l√≥gicas treinadas automaticamente? E como criar novas regras l√≥gicas?** | O "bottleneck do conhecimento" que limitou a IA simb√≥lica cl√°ssica. |
| 3. **Aprendizado Integrado de Fim a Fim** | Projetar modelos onde os componentes neural e simb√≥lico **aprendam juntos** de forma est√°vel, em vez de serem apenas encaixados. **Como manter o sistema audit√°vel, mesmo com este aprendizado paralelo e acoplado?** | O gradiente da rede neural precisa "fluir" atrav√©s do m√≥dulo l√≥gico, o que √© n√£o trivial. **Um sistema de processamento simb√≥lico que incorpora todo o modelo LLM √© poss√≠vel?** |
| 4. **Avalia√ß√£o e Benchmarking** | Falta de **m√©tricas e datasets padronizados** para medir o progresso al√©m da precis√£o bruta, como ganhos em racioc√≠nio e explicabilidade. | Como comparar objetivamente sistemas com arquiteturas neuro-simb√≥licas radicalmente diferentes? **H√° padr√µes/frameworks para o processamento neurosimb√≥lico?** |


### üöÄ Dire√ß√µes Futuras (Roadmap) do Processamento Neurosimb√≥lico 
| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Arquiteturas Modulares e Din√¢micas** | Sistemas onde **m√≥dulos especializados** (neurais para tarefas, simb√≥licos para racioc√≠nio) s√£o ativados dinamicamente conforme a necessidade. **Como codificar o filtro? Com o filtro de assuntos e com gera√ß√£o de bot√µes interativos? Ou com perguntas que funcionam como os bot√µes do atuais agentes de IA?** | Inspirado na unifica√ß√£o/integra√ß√£o entre os padr√µes psicol√≥gicos dos "Sistemas 1 e 2" do c√©rebro humano (Kahneman), com processamento computacional **Sistema 1 & 2**. Ou seja, executa-se o **processamento lento neurosimb√≥lico 2 sobre os s√≠mbolos gerados pelo sistema r√°pido neural 1.** |
| 2. **Racioc√≠nio Probabil√≠stico e Senso Comum** | Integrar **l√≥gica com incerteza** para lidar com conhecimento do mundo real, que √© muitas vezes incompleto ou aproximado. | Combinar redes bayesianas com representa√ß√µes simb√≥licas. |
| 3. **Aprendizado com Poucos Dados e Generaliza√ß√£o** | Usar **conhecimento simb√≥lico como guia ou restri√ß√£o** para o aprendizado neural, reduzindo a necessidade de enormes volumes de dados. | Indu√ß√£o de regras a partir de poucos exemplos ("few-shot learning"). |
| 4. **Aplica√ß√µes em Dom√≠nios Cr√≠ticos** | Foco em √°reas onde **explicabilidade, seguran√ßa e confian√ßa** s√£o obrigat√≥rias: diagn√≥stico m√©dico, controle de sistemas aut√¥nomos, finan√ßas, ciberseguran√ßa. | Onde os sistemas de "caixa preta" puramente neurais s√£o inaceit√°veis. |

### Estado da Arte Atual do Processamento Neurosimb√≥lico (fluxo com Sistema 1 & 2)
- Arquiteturas Poss√≠veis e j√° implementadas na atualidade:
    - DeepProbLog
        - Integra√ß√£o entre sistema 1 e 2 com processamentos probabil√≠sticos
        - L√≥gica probabil√≠stica
        - **Como codificar esta integra√ß√£o?**
    - LTN (logic Tensor Networks)
        - Integra√ß√£o entre sistema 1 e 2 com processamento diferenci√°vel
        - L√≥gica Fuzzy
        - **Como codificar esta integra√ß√£o?**
    - ACT-R
        - Integra√ß√£o entre sistema 1 e 2 com arquitetura cognitiva
        - Tratamento simb√≥lico
        - **Como codificar esta integra√ß√£o?**
    - Soar
        - Integra√ß√£o entre sistema 1 e 2 com arquitetura cognitiva
        - Tratamento simb√≥lico
        - **Como codificar esta integra√ß√£o?** 
    - **Qual a diferen√ßa entre a codifica√ß√£o do fluxo ACT-R e do fluxo Soar?**
        - Posso inovar a integra√ß√£o ACT-R e Soar com a computa√ß√£o qun√¢ntica (IBM), para maior escalabilidade, velocidade?

## Racioc√≠nio L√≥gico
- A IA simb√≥lica usa l√≥gica matem√°tica e teoria dos conjuntos para representar conhecimento.
- Exemplifica com o conceito de que, se "X √© um gato" e "gatos s√£o mam√≠feros", podemos concluir logicamente que "X √© um mam√≠fero".

## Ontologias e Grafos de Conhecimento
### Knowledge Graphs
- S√£o a manifesta√ß√£o moderna da IA simb√≥lica.
- Eles conectam entidades do mundo real (n√≥s) atrav√©s de relacionamentos (arestas).
- Grafos de Conhecimento fornecem fatos curados e audit√°veis

### Ontologias
- Funcionam como o "modelo" ou esquema para o grafo, d  efinindo conceitos, propriedades e restri√ß√µes l√≥gicas.

### Sem√¢ntica
- A sem√¢ntica trata do significado e de como o software interpreta os dados.
- Formatos de dados como JSON n√£o s√£o "f√°ceis de entender" por si s√≥, demonstrando que, sem um contexto definido (grounding), as m√°quinas n√£o compreendem o significado real dos campos.

### Explicabilidade
- O racioc√≠nio simb√≥lico permite rastrear exatamente por que uma resposta foi dada, algo que os LLMs (caixas-pretas) n√£o conseguem fazer facilmente.

### Efici√™ncia Energ√©tica:
- Consultar um Grafo de Conhecimento √© ordens de magnitude mais eficiente do que processar uma resposta via LLM.

### üí° S√≠ntese: O Caminho para a Pr√≥xima Onda em IA
A vis√£o apresentada no artigo √© que a **IA Neurosimb√≥lica n√£o √© apenas uma t√©cnica a mais, mas uma mudan√ßa de paradigma**. Seus princ√≠pios buscam restaurar a **sem√¢ntica, a composicionalidade e a explicabilidade** no cora√ß√£o da IA. Os desafios s√£o profundos, pois envolvem reconciliar duas linguagens computacionais fundamentalmente diferentes. As dire√ß√µes futuras apontam para sistemas mais **modulares, din√¢micos e focados em racioc√≠nio**, que transcendam o paradigma atual de "aprendizado estat√≠stico de correla√ß√µes em dados massivos".

## Futuro: Sistemas H√≠bridos (Neuro-Simb√≥licos)
- Dual Process Models: 
    - Ele cita a ideia de "Racioc√≠nio R√°pido e Lento" de Daniel Kahneman.
    - O LLM seria o processo r√°pido (intuitivo, mas propenso a erros), enquanto o componente simb√≥lico seria o processo lento (deliberativo e confi√°vel).
- Arquitetura H√≠brida:
    - O futuro aponta para o uso de LLMs para interface de linguagem natural (traduzindo perguntas em queries), mas utilizando Grafos de Conhecimento para fornecer as respostas factuais.
- Ontologias e planejamento s√£o essenciais para criar sistemas de IA que sejam confi√°veis, eficientes e explic√°veis.