# Posicionamento da IA Neurosimb√≥lica
- Neurosymbolic Computing mostra-se como uma evolu√ß√£o natural do campo de IA, respondendo cr√≠ticas por **confian√ßa** e **auditoria** dos sistemas de IA baseados em redes neurais.
- O processamento Neurosimb√≥lico defende que deve-se usar s√≠mbolos e l√≥gica para resolver os limites t√©cnicos da Deep Learning (*brittleness* e falta de "entendimento l√≥gico"). A limita√ß√£o de *brittleness* indica que os modelos neurais LLM podem falhar de forma inesperada e perigosa, devido **varia√ß√µes e incertezas presentes nos dados do mundo real**. J√° o problema do entendimento representa a limita√ß√£o l√≥gica de n√£o perceber, por estat√≠sticas da sequ√™ncia de tokens, a **l√≥gica de poss√≠veis argumentos ou etapas complexas**.
- H√° atualmente, no √¢mbito acad√™mico, debate paradigm√°tico entre as escolhas por:
    - Representa√ß√µes Distribu√≠das Neurais
        - vs
    - Representa√ß√µes Localistas Simb√≥licas

## Artigo de Arthur D'√Åvila Garcez, Neuro-simbolic AI: The 3rd Wave
> Artur d‚ÄôAvila Garcez and Lu√≠s C. Lamb  
> City, University of London, UK  
> a.garcez@city.ac.uk  
> Federal University of Rio Grande do Sul, Brazil  
> luislamb@acm.org  
> December, 2020  

- Defende que a melhor forma de avan√ßar os sistemas de IA n√£o √© com este debate paradigm√°tico, mas pensando na **forma como o conhecimento deve ser representado para o ato de aprender algo e para o ato de raciocinar sobre algo**.

- Com base no artigo "Neurosymbolic AI: The 3rd Wave" e no estado da arte sobre processamento neurosimb√≥lico:  

### üìú Princ√≠pios Fundamentais do Processamento Neurosimb√≥lico  

| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Integra√ß√£o H√≠brida** | Neuronal e simb√≥lico n√£o s√£o apenas conectados, mas se **potencializam**. O sistema usa o melhor de cada um destes designs para tarefas espec√≠ficas. | Usa redes neurais para percep√ß√£o (vis√£o, linguagem) e l√≥gica para **racioc√≠nio** e **verifica√ß√£o/auditoria** . |
| 2. **Fundamenta√ß√£o de S√≠mbolos (Symbol Grounding)** | S√≠mbolos abstratos (ex: "cadeira") devem **emergir e ser ancorados** em dados do mundo real (imagens, sensa√ß√µes). | Evita "**s√≠mbolos vazios**" **sem conex√£o sem√¢ntica com o mundo real**. |
| 3. **Composicionalidade e Generaliza√ß√£o no Entendimento dos S√≠mbolos** | O sistema deve poder **combinar conceitos aprendidos** para entender e gerar novas situa√ß√µes n√£o vistas durante o treinamento. (**possibilidade** de flexibilidade da valida√ß√£o l√≥gica) | Entender "empurrar uma cadeira" ao **conhecer** "empurrar" e "cadeira". **O que significa, conforme processamento neurosimb√≥lico, entender "empurrar uma cadeira"?** |
| 4. **Explicabilidade por Design** | O racioc√≠nio deve ser **transparente e rastre√°vel**. Decis√µes podem ser explicadas tanto em termos de dados estat√≠sticos quanto de regras l√≥gicas. **A auditoria mais formal s√≥ pode ocorrer a partir da defini√ß√£o humana e sendo codificada em regras l√≥gicas.** | Fornecer cadeias de infer√™ncia (ex: "Classifiquei como fraude PORQUE a regra X foi violada"). |

### üõë Desafios Principais do Processamento Neurosimb√≥lico 

| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Barreira Representacional** | Conciliar **representa√ß√µes distribu√≠das** (neurais, sub-simb√≥licas) com **representa√ß√µes localistas** (simb√≥licas, l√≥gicas) em uma arquitetura **coesa** √© complexo. **Como codificar tal concilia√ß√£o/transforma√ß√£o?** | **Como um vetor neural se torna um s√≠mbolo discreto para o m√≥dulo l√≥gico manipular?** Como as diferentes frameworks atuais do mercado codificam esta convers√£o? Com filtros sobre os tokens e embeddings pr√©-processados, no fluxo vetorial da rede neural? **Como se codifica este processamento?** |
| 2. **Escalabilidade do Conhecimento** | Criar e manter **bases de conhecimento simb√≥lico** grandes e consistentes √© trabalhoso e dif√≠cil de automatizar totalmente. **Como verificar as regras l√≥gicas treinadas automaticamente? E como criar novas regras l√≥gicas, tanto automaticamente quando por codifica√ß√£o humana?** | Este √© o "***bottleneck*** **do conhecimento**" que limitou a IA simb√≥lica cl√°ssica. Com a maior facilidade da IA Generativa, tal problema de codifica√ß√£o e de design pode ser resolvido? Pode-se criar uma base de conhecimento simb√≥lico a partir dos LLMs atuais? |
| 3. **Aprendizado Integrado de Fim a Fim** | Projetar modelos onde os componentes neural e simb√≥lico **aprendam juntos** de forma est√°vel, em vez de serem apenas encaixados. **Como manter o sistema audit√°vel, mesmo com este aprendizado paralelo e acoplado?** Qual o melhor design para um sistema de IA audit√°vel, com 100% de confiabilidade?| O gradiente da rede neural precisa "fluir" atrav√©s do m√≥dulo l√≥gico, o que √© n√£o trivial. **Um sistema de processamento simb√≥lico que processa todo o fluxo do modelo LLM √© poss√≠vel?** |
| 4. **Avalia√ß√£o e Benchmarking** | Falta de **m√©tricas e datasets padronizados** para medir o progresso. Como medir a precis√£o e os ganhos empresariais devido racioc√≠nio e explicabilidade? | Como comparar objetivamente sistemas com arquiteturas neuro-simb√≥licas radicalmente diferentes? **H√° padr√µes/frameworks para o processamento neurosimb√≥lico?** |


### üöÄ Dire√ß√µes Futuras (Roadmap) do Processamento Neurosimb√≥lico 
| | Descri√ß√£o e Objetivos Principais | Exemplos / Caracter√≠sticas |
| :--- | :--- | :--- |
| 1. **Arquiteturas Modulares e Din√¢micas** | Sistemas onde **m√≥dulos especializados** (neurais para tarefas, e simb√≥licos para racioc√≠nio) s√£o ativados dinamicamente conforme a necessidade. **Como codificar o filtro? Com o filtro de assuntos e com gera√ß√£o de bot√µes interativos? Ou com perguntas que funcionam como os bot√µes do atuais agentes de IA, que autorizam a execu√ß√£o de trabalhos?** | Inspirado na conceitua√ß√£o dos padr√µes psicol√≥gicos do "Sistema 1" e do "Sistema 2" do c√©rebro humano (conforme psic√≥logo Kahneman). Pode ocorrer execu√ß√£o isolada ou integrada, entre estes dois estados mentais. O estado 1 vincula-se com o design neural de um sistema de IA, e o estado 2 vincula-se com o design simb√≥lico de um sistema de IA. A Unifica√ß√£o entre estes 2 Estados ocorre com a nomenclarura "***System 1 & 2***". Neste processamento integrado, executa-se o **processamento lento neurosimb√≥lico 2 sobre os s√≠mbolos gerados pelo sistema r√°pido neural 1.** O que se debate aqui √© como modularizar e como integrar estes dois processamentos. |
| 2. **Racioc√≠nio Probabil√≠stico e Senso Comum** | Integrar **l√≥gica com incerteza** para lidar com conhecimento do mundo real, que √© muitas vezes incompleto ou aproximado. | Combinar redes bayesianas com representa√ß√µes simb√≥licas. (Sistema de ia neurosimb√≥lico deve ser flex√≠vel para configurar o n√≠vel e infer√™ncia aceit√°vel, para a auditoria. Como codificar este "***Reasoning Engine***?") √â um equ√≠voco controlar completamente a defini√ß√£o de todos os poss√≠veis **s√≠mbolos** e o **processamento l√≥gico** sobre todos estes s√≠mbolos. O que se deve fazer √© controlar a infer√™ncia aceit√°vel sobre regras l√≥gicas, mediante a escolha da probabilidade aceit√°vel para os s√≠mbolos e para os predicados l√≥gicos. O sistema deve permitir este controle humano. E tudo deve ser exposto na camada de auditoria. |
| 3. **Aprendizado com Poucos Dados e Generaliza√ß√£o** | Usar **conhecimento simb√≥lico como guia ou restri√ß√£o** para o aprendizado neural, reduzindo a necessidade de enormes volumes de dados. | Indu√ß√£o de regras a partir de poucos exemplos ("few-shot learning") (n√£o entendi ainda, onde tal funcionalidade se insere no design da integra√ß√£o System 1 & 2...). |
| 4. **Aplica√ß√µes em Dom√≠nios Cr√≠ticos** | Foco em √°reas onde **explicabilidade, seguran√ßa e confian√ßa** s√£o obrigat√≥rias: diagn√≥stico m√©dico, controle de sistemas aut√¥nomos, finan√ßas, ciberseguran√ßa. | Onde os sistemas de "caixa preta" puramente neurais s√£o inaceit√°veis pois n√£o conseguem gerar produtos confi√°veis e audit√°veis para a empresa. |

### Estado da Arte do Processamento Neurosimb√≥lico (fluxo com Sistema 1 & 2)

#### Neural-as-Predicate
- Estado da Arte: **Padr√£o** ***Neural-as-Predicate***
    - Exemplos: DeepProbLog, NeurASP e DeepStochLog
    - ***DeepProbLog***
        - **ProbLog** √© uma **extens√£o probabil√≠stica** para o processamento l√≥gico da linguagem Prolog.
        - J√° **DeepProbLog** √© uma **extens√£o do ProbLog** em que predicados probabilisticos s√£o extra√≠dos do processamento feito pelas redes neurais.
        - Processamento do Sistema Neural:
            - Gera predicados probabilisticos
            - A probalidade dos predicados √© definida pela rede neural.
            - Ent√£o, o output desta etapa √©: predicados l√≥gicos com indica√ß√£o de suas probabilidades.
        - Processamento do Sistema Simb√≥lico:
            - Processa os predicados com processamento de l√≥gica probabil√≠stica.
        - **Como codificar a integra√ß√£o Sistema 1 & 2?**
            - Voc√™ codifica regras l√≥gicas probabil√≠sticas para processar predicados extra√≠dos das redes neurais.
            - A codifica√ß√£o do teinamento √© mais simples, pois o erro √© calculado no n√≠vel l√≥gico.
                - O sistema treina a rede neural apenas indiretamente, usando o erro calculado no n√≠vel l√≥gico-probabil√≠stico.
                - O sistema apenas aprende o que √© √∫til para satisfazer regras l√≥gicas.
            - Conhecimento necess√°rio do codificador:
                - Regras L√≥gicas
                - C√°lculos de probabilidade
                - Deep Learning
        - Limita√ß√µes:
            - Infer√™ncia pode ser computacionalmente pesada
            - Escalabilidade ainda √© um desafio
        - Casos de uso atuais:
            - neuro-symbolic reasoning
            - sistemas h√≠bridos explic√°veis
        - Implementa√ß√£o em Python
        - Integra√ß√£o com PyTorch
        - Usa ProbLog, PySDD e SWI-Prolog
        - C√≥digo-fonte: ML-KUEeuven/deepproblog

#### Logic-as-Constraint
- Estado da Arte: **Padr√£o** ***Logic-as-Loss or Logic-as-Constraint***
    - Exemplos: LTN, Semantic Loss, DL2 e SBR.
    - **LTN** (***Logic Tensor Networks***)
        - LTN reinterpreta o processamento da l√≥gica de primeira ordem:
            - Constante da L√≥gica -> vetores (embeddings)
            - Predicados da L√≥gica -> Fun√ß√µes Neurais
            - F√≥rmulas da L√≥gica -> Func√µes Cont√≠nuas [0,1]
            - Valor booleano da L√≥gica -> Grau de Satisfa√ß√£o
        - Usa l√≥gica fuzzy diferenci√°vel:
            - operador AND -> min(a,b)
            - operador OR -> max(a,b)
            - operador NOT -> 1-a
            - operador IMPLIES -> 1-a + b
        - Em resumo, o processamneto LTN √© bastante complexo e requer meses de estudo para entender a forma como transforma o processamento l√≥gico de primeira ordem para o processamento de fun√ß√µes (l√≥gica fuzzy diferenci√°vel).
        - **Como codificar a integra√ß√£o Sistema 1 & 2?**
            - Integra√ß√£o entre sistema 1 e 2 com processamento diferenci√°vel.
            - Uso de fun√ß√µes de frameworks que executam o processamento LTN.
#### ACT-R
- ACT-R
    - Integra√ß√£o entre sistema 1 e 2 com arquitetura cognitiva
    - Tratamento simb√≥lico
    - **Como codificar esta integra√ß√£o?**

#### SOAR
- Soar
    - Integra√ß√£o entre sistema 1 e 2 com arquitetura cognitiva
    - Tratamento simb√≥lico
    - **Como codificar esta integra√ß√£o?** 
- **Qual a diferen√ßa entre a codifica√ß√£o do fluxo ACT-R e do fluxo Soar?**
    - Posso inovar a integra√ß√£o ACT-R e Soar com a computa√ß√£o qun√¢ntica (IBM), para maior escalabilidade, velocidade?

#### Padr√µes do Mercado
| **Padr√£o** | **√â Explicitamente Simb√≥lico** | **Faz Processamento Diferenci√°vel** | **Faz Processamento Probabil√≠stico** | **Status Atual** |
|---|:---:|:---:|:---:|:---:|
| Neural-as_Predicate | ![](/img/icons/check.svg "Sim") | ![](/img/icons/check.svg "Sim") | ![](/img/icons/check.svg "Sim ‚Äî valores cont√≠nuos / fuzzy") | ![](/img/icons/status-emerging.svg "Emergente") |
| Logic-as-Loss | ![](/img/icons/check.svg "Sim ‚Äî l√≥gica expressa como restri√ß√£o") | ![](/img/icons/check.svg "Sim ‚Äî perda diferenci√°vel") | ![](/img/icons/partial.svg "Parcial ‚Äî pode usar soft truth / fuzzy") | ![](/img/icons/status-emerging.svg "Uso em pesquisa e algumas aplica√ß√µes") |
| Symbolic-Prior | ![](/img/icons/check.svg "Sim ‚Äî conhecimento simb√≥lico como prior") | ![](/img/icons/partial.svg "Parcial ‚Äî depende da implementa√ß√£o (soft priors vs r√≠gido)") | ![](/img/icons/partial.svg "Parcial ‚Äî priors podem ser probabil√≠sticos") | ![](/img/icons/status-adopted.svg "Adotado / usado em aplica√ß√µes") |
| Neural Reasoners | ![](/img/icons/cross.svg "N√£o necessariamente ‚Äî geralmente subsimb√≥lico") | ![](/img/icons/check.svg "Sim") | ![](/img/icons/partial.svg "Parcial ‚Äî sa√≠da probabil√≠stica poss√≠vel") | ![](/img/icons/status-emerging.svg "Amplo uso em pesquisa e aplica√ß√µes") |
| Program Induction | ![](/img/icons/check.svg "Sim ‚Äî programas como estruturas simb√≥licas") | ![](/img/icons/partial.svg "Parcial ‚Äî interpretadores diferenci√°veis existem") | ![](/img/icons/partial.svg "Parcial ‚Äî pode ser probabil√≠stico") | ![](/img/icons/status-emerging.svg "Pesquisa ativa / casos de uso espec√≠ficos") |
| LLM + S√≠mbolos | ![](/img/icons/check.svg "Sim ‚Äî integra√ß√£o com m√≥dulos simb√≥licos") | ![](/img/icons/partial.svg "Parcial ‚Äî LLM √© diferenci√°vel; m√≥dulos simb√≥licos podem n√£o ser") | ![](/img/icons/check.svg "Sim ‚Äî LLMs s√£o modelos probabil√≠sticos") | ![](/img/icons/status-adopted.svg "Muito adotado / pr√°tica corrente") |

> **Nota:** √çcones: ![](/img/icons/check.svg) = Sim, ![](/img/icons/cross.svg) = N√£o, ![](/img/icons/partial.svg) = Parcial/Depende. Os **Status** foram avaliados com base em uso atual na pesquisa e em aplica√ß√µes pr√°ticas.

## Racioc√≠nio L√≥gico
- A IA simb√≥lica usa l√≥gica matem√°tica e teoria dos conjuntos para representar conhecimento.
- Exemplifica com o conceito de que, se "X √© um gato" e "gatos s√£o mam√≠feros", podemos concluir logicamente que "X √© um mam√≠fero".

## Ontologias e Grafos de Conhecimento
### Knowledge Graphs
- S√£o a manifesta√ß√£o moderna da IA simb√≥lica.
- Eles conectam entidades do mundo real (n√≥s) atrav√©s de relacionamentos (arestas).
- Grafos de Conhecimento fornecem fatos curados e audit√°veis

### Ontologias
- Funcionam como o "modelo" ou esquema para o grafo, d  efinindo conceitos, propriedades e restri√ß√µes l√≥gicas.

### Sem√¢ntica
- A sem√¢ntica trata do significado e de como o software interpreta os dados.
- Formatos de dados como JSON n√£o s√£o "f√°ceis de entender" por si s√≥, demonstrando que, sem um contexto definido (grounding), as m√°quinas n√£o compreendem o significado real dos campos.

### Explicabilidade
- O racioc√≠nio simb√≥lico permite rastrear exatamente por que uma resposta foi dada, algo que os LLMs (caixas-pretas) n√£o conseguem fazer facilmente.

### Efici√™ncia Energ√©tica:
- Para consultas fractuais bem estruturadas, grafos de conhecimento tendem a ser muito mais eficientes do que infer√™ncias via LLM.

### üí° S√≠ntese: O Caminho para a Pr√≥xima Onda em IA
A vis√£o apresentada no artigo √© que a **IA Neurosimb√≥lica n√£o √© apenas uma t√©cnica a mais, mas uma mudan√ßa de paradigma**. Seus princ√≠pios buscam restaurar a **sem√¢ntica, a composicionalidade e a explicabilidade** no cora√ß√£o da IA. Os desafios s√£o profundos, pois envolvem reconciliar duas linguagens computacionais fundamentalmente diferentes. As dire√ß√µes futuras apontam para sistemas mais **modulares, din√¢micos e focados em racioc√≠nio**, que transcendam o paradigma atual de "aprendizado estat√≠stico de correla√ß√µes em dados massivos".

## Futuro: Sistemas H√≠bridos (Neuro-Simb√≥licos)
- Dual Process Models: 
    - Ele cita a ideia de "Racioc√≠nio R√°pido e Lento" de Daniel Kahneman.
    - O LLM seria o processo r√°pido (intuitivo, mas propenso a erros), enquanto o componente simb√≥lico seria o processo lento (deliberativo e confi√°vel).
- Arquitetura H√≠brida:
    - O futuro aponta para o uso de LLMs para interface de linguagem natural (traduzindo perguntas em queries), mas utilizando Grafos de Conhecimento para fornecer as respostas factuais.
- Ontologias e planejamento s√£o essenciais para criar sistemas de IA que sejam confi√°veis, eficientes e explic√°veis.